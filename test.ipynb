{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, IntegerType, StructField, StringType, DoubleType, DateType\n",
    "\n",
    "# Function to get the max date from the PostgreSQL staging table\n",
    "def get_max_date_from_staging(connection_string, table_name):\n",
    "    \"\"\"Fetch the maximum date from the staging table in PostgreSQL\"\"\"\n",
    "    query = f\"SELECT MAX(date) FROM {table_name};\"\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        conn = psycopg2.connect(connection_string)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        max_date = cursor.fetchone()[0]\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        # If max_date is None, return a default old date (e.g., 2000-01-01)\n",
    "        return max_date if max_date else datetime(2000, 1, 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching max date: {e}\")\n",
    "        return datetime(2000, 1, 1)\n",
    "\n",
    "def fetch_alpha_vantage_data(symbol, api_key, max_date_from_db):\n",
    "    \"\"\"\n",
    "    Fetch daily stock data for a given symbol from the Alpha Vantage API and return as a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    symbol (str): Stock ticker symbol (e.g., \"AAPL\" for Apple Inc.).\n",
    "    api_key (str): API key for Alpha Vantage.\n",
    "    max_date_from_db (datetime): Maximum date from the staging table to control data extraction.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with the time series data for the symbol.\n",
    "    \"\"\"\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize=full&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extracting metadata\n",
    "    meta_data = data.get('Meta Data', {})\n",
    "    description = meta_data.get('1. Information', '')\n",
    "    last_refreshed = meta_data.get('3. Last Refreshed', '')\n",
    "    output_size = meta_data.get('4. Output Size', 'N/A')\n",
    "    time_zone = meta_data.get('5. Time Zone', 'N/A')\n",
    "    symbol = meta_data.get('2. Symbol', '')\n",
    "    \n",
    "    # Initializing empty lists for time series data\n",
    "    dates = []\n",
    "    opens = []\n",
    "    highs = []\n",
    "    lows = []\n",
    "    closes = []\n",
    "    volumes = []\n",
    "    \n",
    "    # Iterate over daily data\n",
    "    for date, daily_data in data.get('Time Series (Daily)', {}).items():\n",
    "        # Convert date to datetime\n",
    "        date = datetime.strptime(date, '%Y-%m-%d')\n",
    "        \n",
    "        # Only add data if the date is greater than the max date from the staging table\n",
    "        if date > max_date_from_db:\n",
    "            dates.append(date)\n",
    "            opens.append(float(daily_data.get('1. open', 0)))\n",
    "            highs.append(float(daily_data.get('2. high', 0)))\n",
    "            lows.append(float(daily_data.get('3. low', 0)))\n",
    "            closes.append(float(daily_data.get('4. close', 0)))\n",
    "            volumes.append(int(daily_data.get('5. volume', 0)))\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'daily_open': opens,\n",
    "        'daily_high': highs,\n",
    "        'daily_low': lows,\n",
    "        'daily_close': closes,\n",
    "        'daily_volume': volumes\n",
    "    })\n",
    "    \n",
    "    # Add metadata columns\n",
    "    df['last_refreshed'] = last_refreshed\n",
    "    df['Output Size'] = output_size\n",
    "    df['Time Zone'] = time_zone\n",
    "    df['Description'] = description\n",
    "    df['symbol'] = symbol  \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Define your PostgreSQL connection string\n",
    "connection_string = \"postgresql://postgres:Chinwe31#@localhost:5432/database_name\"\n",
    "\n",
    "# Define the table name in the staging area\n",
    "table_name = \"alpha_vantage.staging_finance_data\"\n",
    "\n",
    "# Get the maximum date from the PostgreSQL staging table\n",
    "max_date_from_db = get_max_date_from_staging(connection_string, table_name)\n",
    "\n",
    "# Define the list of symbols and your API key\n",
    "symbols = ['TSCO.LON', 'IBM', 'MBG.DEX', 'SHOP.TRT']\n",
    "api_key = \"ML7BZYF38ZPZLHR4\"\n",
    "\n",
    "# Empty list to collect all dataframes\n",
    "df_list = []\n",
    "\n",
    "# Looping through the symbols and fetching data for each\n",
    "for symbol in symbols:\n",
    "    df_symbol = fetch_alpha_vantage_data(symbol, api_key, max_date_from_db)\n",
    "    df_list.append(df_symbol)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(df_combined.head())\n",
    "\n",
    "\n",
    "\n",
    "# Save the combined dataframe to CSV\n",
    "df_combined.to_csv('./alpha_vantage.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
